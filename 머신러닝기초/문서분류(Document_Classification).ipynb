{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CountVectorizer로 벡터화"
      ],
      "metadata": {
        "id": "LITTYKiYmT7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3ky-NJHlskx",
        "outputId": "f82718c8-ed29-4313-931b-fa890d0317f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7919, 130107) (7919,) (3395, 130107) (3395,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "news = fetch_20newsgroups()\n",
        "\n",
        "x = news.data\n",
        "y = news.target\n",
        "\n",
        "cv = CountVectorizer()\n",
        "x = cv.fit_transform(x)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[0])\n",
        "#(0, 56979) >> 0번째에 56979번 인덱스의 단어"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4He9Cw86mYQQ",
        "outputId": "c581f7f1-6689-4c9b-ca06-38652ce613d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 56979)\t1\n",
            "  (0, 50527)\t3\n",
            "  (0, 111322)\t1\n",
            "  (0, 87620)\t1\n",
            "  (0, 95162)\t1\n",
            "  (0, 64095)\t1\n",
            "  (0, 90379)\t1\n",
            "  (0, 89362)\t1\n",
            "  (0, 76032)\t1\n",
            "  (0, 114455)\t3\n",
            "  (0, 68766)\t1\n",
            "  (0, 115475)\t2\n",
            "  (0, 32311)\t1\n",
            "  (0, 123796)\t1\n",
            "  (0, 66608)\t1\n",
            "  (0, 27436)\t1\n",
            "  (0, 56283)\t1\n",
            "  (0, 29573)\t1\n",
            "  (0, 124147)\t1\n",
            "  (0, 28146)\t1\n",
            "  (0, 124332)\t1\n",
            "  (0, 28601)\t1\n",
            "  (0, 124026)\t1\n",
            "  (0, 35805)\t1\n",
            "  (0, 75901)\t2\n",
            "  :\t:\n",
            "  (0, 108950)\t1\n",
            "  (0, 107353)\t1\n",
            "  (0, 16896)\t1\n",
            "  (0, 52651)\t1\n",
            "  (0, 69771)\t1\n",
            "  (0, 64085)\t1\n",
            "  (0, 51142)\t1\n",
            "  (0, 128529)\t3\n",
            "  (0, 27130)\t2\n",
            "  (0, 128133)\t3\n",
            "  (0, 44902)\t2\n",
            "  (0, 45075)\t1\n",
            "  (0, 54775)\t2\n",
            "  (0, 108784)\t1\n",
            "  (0, 128416)\t1\n",
            "  (0, 68759)\t1\n",
            "  (0, 27871)\t2\n",
            "  (0, 105585)\t1\n",
            "  (0, 106904)\t1\n",
            "  (0, 46888)\t1\n",
            "  (0, 123190)\t1\n",
            "  (0, 128616)\t1\n",
            "  (0, 90798)\t1\n",
            "  (0, 23407)\t1\n",
            "  (0, 38960)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n"
      ],
      "metadata": {
        "id": "J9w2KGC-mYNb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 로지스틱 회귀(Logistic Reggression)\n",
        "\n",
        "- 이진분류(0, 1)을 위한 모델 (감성분석) >> 시그모이드 함수 (sigmoid)\n",
        "- 다중분류에는 적합하지 않음\n"
      ],
      "metadata": {
        "id": "AdGz44kpm4K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train, y_train)\n",
        "\n",
        "pred = lr.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxOWY80TnFT6",
        "outputId": "5f16d520-cb7e-49f6-da74-9e08d870d73e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8733431516936672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 서포트 벡터머신(Support Vector Machines)\n",
        "\n",
        "- 회귀, 분류, 이상치 탐지 등에 사용되는 지도학습 방법\n",
        "- 클래스 사이의 경계에 위치한 데이터 포인트 >> 서포트 벡터\n",
        "- 클래스 사이의 결정 경계를 구분하는데 얼마나 중요한지 학습\n",
        "- 서포트 벡터 사이의 마진이 가장 큰 방향으로 학습\n",
        "- 서포트 벡터까지의 거리와 서포트 벡터의 중요도 기반으로 예측"
      ],
      "metadata": {
        "id": "r-CdoLKDoZN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "svm = svm.SVC(kernel = 'linear')\n",
        "svm.fit(x_train, y_train)\n",
        "\n",
        "pred = svm.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndJ5m5tsntTq",
        "outputId": "718b7ac9-4b7b-49c3-c2ee-53d3f7fbc4b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8191458026509573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 나이브 베이스 분류기 (Native Bayers Classification)\n",
        "\n",
        "- 베이즈 정리를 적용한 확률적 분류 알고리즘\n",
        "- 모든 특성이 독립임을 가정\n",
        "- 입력 특성에 따라 3개의 분류기 존재\n",
        "  - 가우시안 나이브\n",
        "  - 베르누이 나이브\n",
        "  - 다항 나이브"
      ],
      "metadata": {
        "id": "rDnTd3mSpH6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DTM을 이용한 나이브 베이즈"
      ],
      "metadata": {
        "id": "SZd7HEnJpfyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(x_train, y_train)\n",
        "\n",
        "pred = nb.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jOye9i1ntQO",
        "outputId": "92b4d232-0abf-4acc-f1c7-453a294adc51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8279823269513991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf-idf를 이용한 정확도 향상"
      ],
      "metadata": {
        "id": "uGkoxlb-pswX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf = TfidfTransformer()\n",
        "x_train_tf = tfidf.fit_transform(x_train)\n",
        "x_test_tf = tfidf.fit_transform(x_test)\n",
        "\n",
        "nb.fit(x_train_tf, y_train)\n",
        "\n",
        "pred = nb.predict(x_test_tf)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWDk1eafntOZ",
        "outputId": "5263a901-c4da-43d4-822c-2565a9f204f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8306332842415317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 결정트리 (Decision Tree)\n",
        "\n",
        "- 분류와 회귀에 사용되는 지도 학습 방법\n",
        "- 결정 규칙을 통해 값을 예측\n",
        "- if-then-else 결정 규칙을 통해 데이터 학습\n",
        "- 트리의 깊이가 깊을 수록 복잡한 모델"
      ],
      "metadata": {
        "id": "GoQcOEaXqIeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "pred = dt.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_gLgOT2ntMa",
        "outputId": "f2ecdc0e-50f5-4cc8-f570-b3ce559a9553"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6306332842415316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost\n",
        "\n",
        "- 트리기반의 앙상블 기법\n"
      ],
      "metadata": {
        "id": "OgMtMf_Zqo6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=30, learning_rate=0.05, max_depth=3)\n",
        "xgb.fit(x_train, y_train)\n",
        "\n",
        "pred = xgb.predict(x_test)\n",
        "acc = accuracy_score(pred, y_test)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EssdI8bGqa4F",
        "outputId": "edbc9899-034f-4298-d020-f26479db96c7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7072164948453609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 교차검증\n",
        "\n",
        "- 일반검증은 학습 데이터(train)가 테스트 데이터로 사용 x\n",
        "- 데이터를 n개의 집합으로 나눔 >> 정확도 계산 >> 학습데이터로 사용된 데이터도 테스트 데이터로 사용\n",
        "- 모델의 일반화가 잘 되어 있는지 평가 가능\n",
        "- 나이브 베이즈 모델을 교차검증"
      ],
      "metadata": {
        "id": "4HUz3tbDrAOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(nb, x, y, cv=5)\n",
        "print(scores, scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYTakQs5qzt7",
        "outputId": "398a0d8b-7ec0-480d-c5f5-ca222a3bbfb0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.83870968 0.83826779 0.82368537 0.83031374 0.83642794] 0.833480903927519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 정밀도와 재현률\n",
        "* 정밀도(accuracy)는 양성 클래스(정답)으로 예측한 샘플이 양성 클래스일 확률을 의미\n",
        "* 모델이 얼마나 양성 클래스를 잘 예측하는지를 나타냄\n",
        "* 재현률(recall)은 양성 클래스인 샘플에서 모델이 양성 클래스로 예측한 샘플 비율을 의미하며, 모델이 얼마나 실제 상황을 재현하는지를 나타냄\n",
        "* 정밀도와 재현율의 가중조화평균인 F1-score라는 지표는 정확도에 비해 더 효과적인 모델 분석 지표로 알려져 있음\n",
        "* 직접 계산할 수도 있으나, scikit-learn은 이를 편리하게 계산해주는 함수를 제공"
      ],
      "metadata": {
        "id": "PJoHDnD0rwQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 다중 클래스 분류 문제에서 정밀도와 재현률을 계산할 때는 클래스간의 지표를 어떻게 합칠지 지정 필요\n",
        "\n",
        "  * None - 클래스간 지표를 합치지 말고 그대로 출력\n",
        "  * micro - 정밀도와 재현률이 같음, 이로 인해 f1-score도 정밀도, 재현률과 동일\n",
        "  * macro - 클래스간 지표를 단순 평균한 값\n",
        "  * weighted - 클래스간 지표를 가중 평균한 값"
      ],
      "metadata": {
        "id": "BO46Q3Tdr720"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(pred, y_test, average='micro')\n",
        "recall = recall_score(pred, y_test, average='micro')\n",
        "f1 = f1_score(pred, y_test, average='micro')\n",
        "\n",
        "print(precision, recall, f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4-CejvbrcYv",
        "outputId": "60a8881a-d3c3-4d13-f8c4-06abb5d34ea7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7072164948453609 0.7072164948453609 0.7072164948453608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision = precision_score(pred, y_test, average='macro')\n",
        "recall = recall_score(pred, y_test, average='macro')\n",
        "f1 = f1_score(pred, y_test, average='macro')\n",
        "\n",
        "print(precision, recall, f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiM52dlTsVh9",
        "outputId": "902492bf-a960-4499-e156-fc6c2729214a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7037355124622485 0.7483448814726981 0.7179093463021038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 그리드 검색을 이용한 파라미터 최적화\n",
        "\n",
        "* 그리드 검색을 사용하면 분류기에 사용하는 파라미터 최적화 가능\n",
        "* 그리드 검색을 통해 앞서 구성한 나이브 베이즈 모델의 'alpha' 파라미터를 최적화시키는 예제\n",
        "\n",
        "* `estimator`: 사용 모델 객체     \n",
        "* `param_grid`: 사용 객체:지정 파라미터 리스트로 구성된 딕셔너리    \n",
        "* `scoring`: 최적화하고자 하는 성능 지표   \n",
        "* `cv`: 교차 검증 분할 개수      "
      ],
      "metadata": {
        "id": "cFLSm6VZr-VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "gs = GridSearchCV(estimator=nb, param_grid={'alpha':[0.0006, 0.0008, 0.001]}, scoring='accuracy', cv=10)\n",
        "gs.fit(x, y)\n",
        "\n",
        "print(gs.best_score_)\n",
        "print(gs.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL2x4ITusBOW",
        "outputId": "a85611b6-5421-4243-db16-50805b5c4854"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8897820965842167\n",
            "{'alpha': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0FU4qGm5sqig"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}